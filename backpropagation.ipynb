{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(60000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "\n",
    "X, y = loadlocal_mnist(\n",
    "        images_path='mnist_data/train-images.idx3-ubyte', \n",
    "        labels_path='mnist_data/train-labels.idx1-ubyte')\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "nb_classes = 10\n",
    "targets = y.reshape(-1)\n",
    "one_hot_targets = np.eye(nb_classes)[targets]\n",
    "\n",
    "print(one_hot_targets.shape)\n",
    "\n",
    "plt.imshow(X[0, :].reshape(28, 28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (784, 1)\n",
      "First layer shape:  (100, 784)\n",
      "Hidden layer shape:  (100, 1)\n",
      "Second layer shape:  (10, 100)\n",
      "Output shape:  (10, 1)\n",
      "Ground truth shape:  (10, 1)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "inputs = 784\n",
    "num_hidden = 100\n",
    "outputs = 10\n",
    "\n",
    "def sigmoid(x):\n",
    "    return (1 + np.exp(-x))**-1\n",
    "\n",
    "# One should do this numerically though and not use a function\n",
    "# store num_activations\n",
    "# gradients <- num_activations*(1-num_activations)\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "def loss(y, y_hat):\n",
    "    return np.sum(np.square(y-y_hat))\n",
    "\n",
    "# Create random input and output\n",
    "batch_size = 1\n",
    "\n",
    "#FIXME: transform data by normalizing it\n",
    "# ie. divide by 255\n",
    "y_k = one_hot_targets[0:batch_size, :].transpose()\n",
    "x_i = X[0:batch_size, :].transpose() / 255\n",
    "                     \n",
    "w_ji = np.random.randn(num_hidden, inputs)\n",
    "w_kj = np.random.randn(outputs, num_hidden)\n",
    "b_j = np.matmul(w_ji, x_i)\n",
    "V_j = sigmoid(b_j)\n",
    "b_k = np.matmul(w_kj, V_j)\n",
    "O_k = sigmoid(b_k)\n",
    "\n",
    "# This function does not work then\n",
    "def feed_forward(x_i):\n",
    "    global b_j, V_j, b_k, O_k\n",
    "    b_j = np.matmul(w_ji, x_i)\n",
    "    V_j = sigmoid(b_j)\n",
    "    b_k = np.matmul(w_kj, V_j)\n",
    "    O_k = sigmoid(b_k)\n",
    "\n",
    "feed_forward(x_i)\n",
    "\n",
    "print(\"Input shape: \", x_i.shape)\n",
    "print(\"First layer shape: \", w_ji.shape)\n",
    "print(\"Hidden layer shape: \", V_j.shape)\n",
    "print(\"Second layer shape: \", w_kj.shape)\n",
    "print(\"Output shape: \", O_k.shape)\n",
    "\n",
    "print(\"Ground truth shape: \", y_k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta_k:  (10, 1)\n",
      "update term second layer:  (10, 100)\n",
      "DELTA_k:  (1, 100)\n",
      "update term first layer:  (100, 784)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Shape of neural network is\n",
    "784 -> 100 -> 10\n",
    "\n",
    "w_ji.shape = [784, 100]\n",
    "w_kj.shape = [100, 10]\n",
    "\n",
    "'''\n",
    "\n",
    "# Errors for the output layer\n",
    "delta_k = (y_k-O_k)*sigmoid_prime(b_k)\n",
    "print(\"delta_k: \", delta_k.shape)\n",
    "\n",
    "# The propagated error for the second weight matrix\n",
    "delta_w_kj = np.matmul(delta_k, V_j.transpose())\n",
    "print(\"update term second layer: \", delta_w_kj.shape)\n",
    "\n",
    "# The propagated error for the first weightmatrix\n",
    "DELTA_k = np.multiply(np.dot(delta_k.transpose(), w_kj), sigmoid_prime(b_j).transpose())\n",
    "print(\"DELTA_k: \", DELTA_k.shape)\n",
    "delta_w_ji = np.matmul(x_i, DELTA_k).transpose()\n",
    "print(\"update term first layer: \", delta_w_ji.shape)\n",
    "\n",
    "def backpropagation():\n",
    "    global delta_k, delta_w_kj, DELTA_k, delta_w_ji, y_k, O_k\n",
    "    # Second layer update term\n",
    "    delta_k = (y_k-O_k)*sigmoid_prime(b_k)\n",
    "    delta_w_kj = np.matmul(delta_k, V_j.transpose())\n",
    "    # First layer update term\n",
    "    DELTA_k = np.multiply(np.dot(delta_k.transpose(), w_kj), sigmoid_prime(b_j).transpose())\n",
    "    delta_w_ji = np.matmul(x_i, DELTA_k).transpose()\n",
    "\n",
    "def update_weights():\n",
    "    global delta_w_kj, delta_w_ji, w_kj, w_ji\n",
    "    w_ji = w_ji + lr*delta_w_ji\n",
    "    w_kj = w_kj + lr*delta_w_kj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value without training:  4.262097969448646\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss value without training: \", loss(y_k, O_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Iteration:  10000\n",
      "Iteration:  20000\n",
      "Iteration:  30000\n",
      "Iteration:  40000\n",
      "Iteration:  50000\n",
      "Iteration:  60000\n",
      "Iteration:  70000\n",
      "Iteration:  80000\n",
      "Iteration:  90000\n",
      "Iteration:  100000\n",
      "Iteration:  110000\n",
      "Iteration:  120000\n",
      "Iteration:  130000\n",
      "Iteration:  140000\n",
      "Iteration:  150000\n",
      "Iteration:  160000\n",
      "Iteration:  170000\n",
      "Iteration:  180000\n",
      "Iteration:  190000\n",
      "Iteration:  200000\n",
      "Iteration:  210000\n",
      "Iteration:  220000\n",
      "Iteration:  230000\n",
      "Iteration:  240000\n",
      "Iteration:  250000\n",
      "Iteration:  260000\n",
      "Iteration:  270000\n",
      "Iteration:  280000\n",
      "Iteration:  290000\n"
     ]
    }
   ],
   "source": [
    "# N - Number of training iterations\n",
    "N = 5*60000\n",
    "batch_size = 2\n",
    "\n",
    "# Training loop\n",
    "j = 0\n",
    "for i in range(N):\n",
    "    if i % 10000 == 0:\n",
    "        print(\"Iteration: \", i)\n",
    "    if j > 60000-1:\n",
    "        j = 0\n",
    "        \n",
    "    feed_forward(X[j:(j+1), :].transpose())\n",
    "    backpropagation()\n",
    "    update_weights()\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.69634125e-06 9.96064957e-08 1.61733199e-04 3.90351644e-06\n",
      " 4.28920275e-06 9.99949155e-01 4.67329766e-07 3.48391272e-06\n",
      " 1.90834807e-04 1.32351083e-07]\n",
      "6\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x182b0411308>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = 3\n",
    "feed_forward(X[ind, :].transpose())\n",
    "print(O_k)\n",
    "print(np.argmax(O_k)+1)\n",
    "print(targets[ind])\n",
    "plt.imshow(X[ind, :].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network from Welchlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(105, 4)\n",
      "(105, 3)\n",
      "(45, 4)\n",
      "(45, 3)\n",
      "[[0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as ds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = ds.load_iris()\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "N = len(y)\n",
    "\n",
    "rand_ind = np.random.choice(N, N, replace=False)\n",
    "\n",
    "split = int(0.7*N)\n",
    "\n",
    "train_X = X[rand_ind[0:split]]\n",
    "train_y = np.expand_dims(y[rand_ind[0:split]], axis=1)\n",
    "\n",
    "nb_classes = len(np.unique(y))\n",
    "print(nb_classes)\n",
    "targets = train_y.reshape(-1)\n",
    "one_hot_train_y = np.eye(nb_classes)[targets]\n",
    "\n",
    "test_X = X[rand_ind[split:]]\n",
    "test_y = np.expand_dims(y[rand_ind[split:]], axis=1)\n",
    "targets = test_y.reshape(-1)\n",
    "one_hot_test_y = np.eye(nb_classes)[targets]\n",
    "\n",
    "print(train_X.shape)\n",
    "print(one_hot_train_y.shape)\n",
    "\n",
    "print(test_X.shape)\n",
    "print(one_hot_test_y.shape)\n",
    "\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class neural_network:\n",
    "    def __init__(self, activation_function, derivative_act_func, input_size, num_classes):\n",
    "        # Define hyper-parameters\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_size = 100\n",
    "        self.output_size = num_classes\n",
    "        self.activation_function = activation_function\n",
    "        self.derivative_act_func = derivative_act_func\n",
    "        \n",
    "        self.W1 = np.random.randn(self.input_size, self.hidden_layer_size)\n",
    "        self.W2 = np.random.randn(self.hidden_layer_size, self.output_size)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # Pass data through network\n",
    "        self.z2 = np.dot(X, self.W1)\n",
    "        self.a2 = self.activation_function(self.z2)\n",
    "        self.z3 = np.dot(self.a2, self.W2)\n",
    "        yhat = self.activation_function(self.z3)\n",
    "        return yhat\n",
    "    \n",
    "    def cost_function(self, X, y):\n",
    "        self.yhat = self.forward(X)\n",
    "        C = np.sum(0.5*(y-self.yhat)**2)\n",
    "        return C\n",
    "    \n",
    "    def cost_function_prime(self, X, y):\n",
    "        self.yhat = self.forward(X)\n",
    "        delta3 = np.multiply(-(y-self.yhat), self.derivative_act_func(self.z3))\n",
    "        dJdW2 = np.dot(self.a2.transpose(), delta3)\n",
    "        \n",
    "        delta2 = np.multiply(np.dot(delta3, self.W2.transpose()), self.derivative_act_func(self.z2))\n",
    "        dJdW1 = np.dot(X.transpose(), delta2)\n",
    "        return dJdW1, dJdW2\n",
    "    \n",
    "    def get_params(self):\n",
    "        params = np.concatenate((self.W1.ravel(), self.W2.ravel()))\n",
    "        return params\n",
    "    \n",
    "    def set_params(self, params):\n",
    "        W1_start = 0\n",
    "        W1_end = self.input_size*self.hidden_layer_size\n",
    "        self.W1 = params[W1_start:W1_end].reshape((self.input_size, self.hidden_layer_size))\n",
    "        W2_end = W1_end + self.hidden_layer_size*self.output_size\n",
    "        self.W2 = params[W1_end:W2_end].reshape((self.hidden_layer_size, self.output_size))\n",
    "    \n",
    "    def compute_gradients(self, X, y):\n",
    "        dJdW1, dJdW2 = self.cost_function_prime(X, y)\n",
    "        gradients = np.concatenate((dJdW1.ravel(), dJdW2.ravel()))\n",
    "        return gradients\n",
    "\n",
    "def sigmoid(X):\n",
    "    return 1/(1 + np.exp(-X))\n",
    "\n",
    "def sigmoid_prime(X):\n",
    "    return sigmoid(X)*(1-sigmoid(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "input_size = train_X.shape[1]\n",
    "print(input_size)\n",
    "\n",
    "nn = neural_network(sigmoid, sigmoid_prime, input_size, nb_classes)\n",
    "\n",
    "ind = 1\n",
    "X1, y1 = np.expand_dims(X[ind,:], axis=0), np.expand_dims(y[ind], axis=0)\n",
    "nn.forward(X1)\n",
    "result = nn.cost_function_prime(X1, y1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9579962154585615e-09\n"
     ]
    }
   ],
   "source": [
    "def compute_numerical_gradient(N, X, y):\n",
    "    params_initial = N.get_params()\n",
    "    num_grad = np.zeros(params_initial.shape)\n",
    "    perturb = np.zeros(params_initial.shape)\n",
    "    p = 1e-4\n",
    "    \n",
    "    N.set_params(params_initial + p)\n",
    "    grad1 = N.compute_gradients(X, y)\n",
    "    N.set_params(params_initial - p)\n",
    "    grad2 = N.compute_gradients(X, y)\n",
    "    \n",
    "    num_grad = (grad1-grad2)/2\n",
    "    return num_grad\n",
    "\n",
    "def compute_numerical_gradient(N, X, y):\n",
    "        paramsInitial = N.get_params()\n",
    "        numgrad = np.zeros(paramsInitial.shape)\n",
    "        perturb = np.zeros(paramsInitial.shape)\n",
    "        e = 1e-4\n",
    "\n",
    "        for p in range(len(paramsInitial)):\n",
    "            #Set perturbation vector\n",
    "            perturb[p] = e\n",
    "            N.set_params(paramsInitial + perturb)\n",
    "            loss2 = N.cost_function(X, y)\n",
    "            \n",
    "            N.set_params(paramsInitial - perturb)\n",
    "            loss1 = N.cost_function(X, y)\n",
    "\n",
    "            #Compute Numerical Gradient\n",
    "            numgrad[p] = (loss2 - loss1) / (2*e)\n",
    "\n",
    "            #Return the value we changed to zero:\n",
    "            perturb[p] = 0\n",
    "            \n",
    "        #Return Params to original value:\n",
    "        N.set_params(paramsInitial)\n",
    "\n",
    "        return numgrad \n",
    "\n",
    "num_grad = compute_numerical_gradient(nn, X1, y1)\n",
    "grad = nn.compute_gradients(X1, y1)\n",
    "norm = np.linalg.norm\n",
    "\n",
    "print(norm(grad-num_grad)/norm(grad+num_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which means it seems to work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "class trainer:\n",
    "    def __init__(self, N):\n",
    "        # N denotes neural network\n",
    "        self.N = N\n",
    "    \n",
    "    def callback_f(self, params):\n",
    "        self.N.set_params(params)\n",
    "        self.J.append(self.N.cost_function(self.X, self.y))\n",
    "    \n",
    "    def cost_function_wrapper(self, params, X, y):\n",
    "        self.N.set_params(params)\n",
    "        cost = self.N.cost_function(X, y)\n",
    "        grad = self.N.compute_gradients(X, y)\n",
    "        return cost, grad\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        # Variables X and y which the callback will reference\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        # Keeping track of the cost function\n",
    "        self.J = []\n",
    "        params0 = self.N.get_params()\n",
    "        \n",
    "        options = {'maxiter': 100, 'disp' : True}\n",
    "        _res = optimize.minimize(self.cost_function_wrapper, params0, jac=True, method='BFGS', \\\n",
    "                                 args=(X, y), options=options, callback=self.callback_f)\n",
    "\n",
    "        self.N.set_params(_res.x)\n",
    "        self.optimizationResults = _res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.trainer at 0x7fd3724ad358>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = trainer(nn)\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.000000\n",
      "         Iterations: 92\n",
      "         Function evaluations: 113\n",
      "         Gradient evaluations: 113\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T.train(train_X, one_hot_train_y)\n",
    "\n",
    "plt.plot(T.J)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "yhat_ohe = T.N.forward(test_X)\n",
    "yhat = np.argmax(yhat_ohe, axis=1)\n",
    "\n",
    "correctly_classified = yhat == test_y.squeeze()\n",
    "\n",
    "acc = np.sum(correctly_classified)/len(correctly_classified)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
